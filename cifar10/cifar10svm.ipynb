{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog&Cat  SVM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team members:\n",
    "* Zhichun Wang ID 19024898\n",
    "* Ziyi Wang   ID 18042783\n",
    "* Youzhi Lei  ID 19039281"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "* Using SVM to classify some kinds of vehicles & animals\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information about datasets\n",
    "Labeled vehicles and animals from:\n",
    "    Images of various types of vehicles and animals http://www.cs.toronto.edu/%7Ekriz/cifar.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import patsy\n",
    "import os\n",
    "from PIL import Image \n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.2\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    return cv2.resize(image, size).flatten()\n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "    # handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "    # if imutils.is_cv2():\n",
    "    #    hist = cv2.normalize(hist)\n",
    "    #print(\"line2\")\n",
    "    # otherwise, perform \"in place\" normalization in OpenCV 3\n",
    "    #else:\n",
    "    cv2.normalize(hist, hist)\n",
    "    \n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "#sns.set_style(\"whitegrid\")\n",
    "rcParams['figure.dpi'] = 150\n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "rcParams['figure.figsize'] = 10,8\n",
    "rcParams['font.size'] = 14\n",
    "rcParams['axes.labelsize'] = 'large'\n",
    "rcParams['xtick.labelsize'] = 14\n",
    "rcParams['ytick.labelsize'] = 14\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dp1/Ml-project1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "#Please put the data to current location, Thanks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is a b'frog' . Its label is 6\n",
      "10 categories: [b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck']\n"
     ]
    }
   ],
   "source": [
    "DATADIR = r\"/home/dp1/Downloads/cifar-10-batches-py/\"\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Choose one image randomly, just to display it\n",
    "batch = unpickle(DATADIR+\"data_batch_1\")\n",
    "\n",
    "# For more detail on the dataset files, see http://www.cs.toronto.edu/%7Ekriz/cifar.html \n",
    "IMG_SIZE = 32 # each image in the dataset is 32*32, color\n",
    "img_array = batch[b'data'][0].reshape(3, 1024)\n",
    "ziplist = list(zip(img_array[2], img_array[1], img_array[0]))\n",
    "newarray = np.array(ziplist).reshape(IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "#plt.imshow(newarray)\n",
    "#plt.show\n",
    "\n",
    "img_array = cv2.cvtColor(newarray, cv2.COLOR_BGR2GRAY)\n",
    "#plt.imshow(img_array, cmap='gray')\n",
    "#plt.show\n",
    "\n",
    "metafile = unpickle(DATADIR+\"batches.meta\") \n",
    "print(\"This image is a\", metafile[b'label_names'][batch[b'labels'][0]], \". Its label is\", batch[b'labels'][0])\n",
    "\n",
    "CATEGORIES = []\n",
    "for i in range(len(metafile[b'label_names'])):\n",
    "    CATEGORIES.append(metafile[b'label_names'][i])\n",
    "\n",
    "print(len(metafile[b'label_names']), \"categories:\", CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 images are in data_batch_5\n",
      "10000 images are in data_batch_2\n",
      "10000 images are in data_batch_3\n",
      "10000 images are in data_batch_4\n",
      "10000 images are in test_batch\n",
      "10000 images are in data_batch_1\n"
     ]
    }
   ],
   "source": [
    "rawImages = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "def create_training_data():    \n",
    "    for batchfile in os.listdir(DATADIR):        \n",
    "        if (batchfile.startswith(\"data_batch_\") or batchfile == 'test_batch'):                \n",
    "            batch = unpickle(os.path.join(DATADIR, batchfile))\n",
    "            print(len(batch[b'data']), \"images are in\", batchfile)\n",
    "            for i in range(len(batch[b'data'])): # There should be 10000 images in each batch                    \n",
    "                # 1024 red values, then 1024 green values, then 1024 blue values\n",
    "                img_array = batch[b'data'][i].reshape(3, 1024) \n",
    "                #print(\"shape is\", img_array.shape)\n",
    "                # Note that OpenCV needs BGR instead of RGB\n",
    "                ziplist = list(zip(img_array[2], img_array[1], img_array[0])) \n",
    "                img_array = np.array(ziplist).reshape(IMG_SIZE, IMG_SIZE, 3)\n",
    "                pixels = image_to_feature_vector(img_array)    \n",
    "                hist = extract_color_histogram(img_array)       \n",
    "                label = batch[b'labels'][i]\n",
    "                \n",
    "                rawImages.append(pixels)\n",
    "                features.append(hist)\n",
    "                labels.append(label)                    \n",
    "create_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(rawImages))\n",
    "print(len(features))\n",
    "print(len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 180.00MB\n",
      "[INFO] features matrix: 120.00MB\n"
     ]
    }
   ],
   "source": [
    "# show some information on the memory consumed by the raw images\n",
    "# matrix and features matrix\n",
    "rawImages = np.array(rawImages)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(rawImages.nbytes / (1024 * 1000.0)))\n",
    "print(\"[INFO] features matrix: {:.2f}MB\".format(features.nbytes / (1024 * 1000.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#features_scaled = preprocessing.scale(features)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features_scaled  = scaler.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits, using 85%\n",
    "# of the data for training and the remaining 15% for testing\n",
    "(trainRI, testRI, trainRL, testRL) = train_test_split(rawImages, labels, test_size=0.15, random_state=42)\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(features, labels, test_size=0.15, random_state=42)\n",
    "#(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(features_scaled, labels, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedRandom name='rawImagesdataset.pickle'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "dataset = {\n",
    "    'trainRI': trainRI,\n",
    "    'testRI' : testRI,\n",
    "    'trainRL': trainRL,\n",
    "    'testRL' : testRL\n",
    "}\n",
    "filename = 'rawImagesdataset.pickle'\n",
    "\n",
    "outfile = open(filename,'wb+')\n",
    "print(outfile)\n",
    "pickle.dump(dataset,outfile)\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedRandom name='features_scaleddataset.pickle'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "dataset = {\n",
    "    'trainFeat': trainFeat,\n",
    "    'testFeat' : testFeat,\n",
    "    'trainLabels': trainLabels,\n",
    "    'testLabels' : testLabels\n",
    "}\n",
    "filename = 'features_scaleddataset.pickle'\n",
    "\n",
    "outfile = open(filename,'wb+')\n",
    "print(outfile)\n",
    "pickle.dump(dataset,outfile)\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] raw pixel accuracy: 35.34%\n"
     ]
    }
   ],
   "source": [
    "# k-NN\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(trainRI, trainRL)\n",
    "acc = model.score(testRI, testRL)\n",
    "#print(\"[INFO] k-NN classifier: k=%d\" % args[\"neighbors\"])\n",
    "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] neural network raw pixel accuracy: 9.83%\n"
     ]
    }
   ],
   "source": [
    "#neural network\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model = MLPClassifier(hidden_layer_sizes=(32,), max_iter=1000, alpha=1e-4,\n",
    "                      solver='sgd', tol=1e-4, random_state=1,\n",
    "                      learning_rate_init=.1)\n",
    "model.fit(trainRI, trainRL)\n",
    "acc = model.score(testRI, testRL)\n",
    "print(\"[INFO] neural network raw pixel accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] evaluating histogram accuracy...\n",
      "[INFO] neural network histogram accuracy: 38.83%\n"
     ]
    }
   ],
   "source": [
    "#neural network\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating histogram accuracy...\")\n",
    "model = MLPClassifier(hidden_layer_sizes=(32,), max_iter=1000, alpha=1e-4,\n",
    "                      solver='sgd', tol=1e-4, random_state=1,\n",
    "                      learning_rate_init=.1)\n",
    "model.fit(trainFeat, trainLabels)\n",
    "acc = model.score(testFeat, testLabels)\n",
    "print(\"[INFO] neural network histogram accuracy: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('rawImagesdataset.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    rawImagesdataset = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "(trainRI, testRI, trainRL, testRL) =   rawImagesdataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] evaluating raw pixel accuracy...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'trainRI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1d8cf4fab741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] evaluating raw pixel accuracy...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainRI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainRL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestRI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestRL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] SVM-SVC raw pixel accuracy: {:.2f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    148\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'trainRI'"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model = SVC(max_iter=1000,class_weight='balanced')\n",
    "model.fit(trainRI, trainRL)\n",
    "acc = model.score(testRI, testRL)\n",
    "print(\"[INFO] SVM-SVC raw pixel accuracy: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('features_scaleddataset.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    features_scaleddataset = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "(trainRI, testRI, trainRL, testRL) =   features_scaleddataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] evaluating histogram accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SVM-SVC histogram accuracy: 51.01549973%\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] evaluating histogram accuracy...\")\n",
    "model = SVC(max_iter=1000,class_weight='balanced')\n",
    "model.fit(trainFeat, trainLabels)\n",
    "acc = model.score(testFeat, testLabels)\n",
    "print(\"[INFO] SVM-SVC histogram accuracy: {:.8f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
