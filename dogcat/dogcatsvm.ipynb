{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog&Cat  SVM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team members:\n",
    "* Ziyi Wang   ID 18042783\n",
    "* Youzhi Lei  ID 19039281"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "* Using SVM to classify the dog&cat\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information about datasets\n",
    "#### Labeled dogs and cats from Microsoft\n",
    "* Dogs and Cats image https://www.microsoft.com/en-us/download/details.aspx?id=54765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import patsy\n",
    "import os\n",
    "from PIL import Image \n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.2\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(50, 50)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    return cv2.resize(image, size).flatten()\n",
    "\n",
    "def extract_color_histogram(image, bins=(32, 32, 32)):\n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "    # handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "    # if imutils.is_cv2():\n",
    "    #    hist = cv2.normalize(hist)\n",
    "    #print(\"line2\")\n",
    "    # otherwise, perform \"in place\" normalization in OpenCV 3\n",
    "    #else:\n",
    "    cv2.normalize(hist, hist)\n",
    "    \n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "#sns.set_style(\"whitegrid\")\n",
    "rcParams['figure.dpi'] = 150\n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "rcParams['figure.figsize'] = 10,8\n",
    "rcParams['font.size'] = 14\n",
    "rcParams['axes.labelsize'] = 'large'\n",
    "rcParams['xtick.labelsize'] = 14\n",
    "rcParams['ytick.labelsize'] = 14\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dp1/fredwork\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "#Please put the data to current location, Thanks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset \n",
    "#test one image and show \n",
    "DATADIR = \"../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages\"\n",
    "CATEGORIES = [\"Dog\",\"Cat\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/4367.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/10747.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/5604.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/8730.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/10797.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/3136.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/3288.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/11702.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/11410.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/2877.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/Thumbs.db\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/10401.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/6059.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/9188.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/2688.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/6238.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/11853.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/5736.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/11675.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/10158.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/1308.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/1866.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/7969.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/7369.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/7133.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/7459.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/3588.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/7112.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/6718.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/11849.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Dog/2384.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/10125.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/8470.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/3491.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/660.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/9565.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/7968.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/4833.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/10404.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/Thumbs.db\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/11874.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/11565.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/3300.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/9171.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/11210.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/850.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/936.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/5553.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/10501.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/2663.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/11935.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/9778.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/7978.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/10820.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/140.jpg\n",
      "../Documents/fred/codes/machinelearning2019/kagglecatsanddogs/PetImages/Cat/666.jpg\n"
     ]
    }
   ],
   "source": [
    "rawImages = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        #conver the dog and cat to numerical value 0/1\n",
    "        label = CATEGORIES.index(category)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                #read  \n",
    "                imgpath = os.path.join(path,img)\n",
    "                \n",
    "                img_array = cv2.imread(imgpath)\n",
    "\n",
    "                pixels = image_to_feature_vector(img_array)\n",
    "                \n",
    "                hist = extract_color_histogram(img_array)\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(imgpath)\n",
    "                continue\n",
    "                \n",
    "            rawImages.append(pixels)\n",
    "            features.append(hist)\n",
    "            labels.append(label)\n",
    "\n",
    "            \n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n",
      "24946\n",
      "24946\n"
     ]
    }
   ],
   "source": [
    "print(len(rawImages))\n",
    "print(len(features))\n",
    "print(len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate dataset\n",
    "import random\n",
    "random.shuffle(training_data)\n",
    "#random.shuffle(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8e3d514dd0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#followed by a color histogram to characterize the color distribution of the pixels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# in the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_to_feature_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_color_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# add the messages we got to the raw images, features, and labels matricies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize the raw pixel intensities matrix, the features matrix,\n",
    "# and labels list\n",
    "rawImages = []\n",
    "features = []\n",
    "labels = []\n",
    "for features, label in training_data:\n",
    "        # extract raw pixel intensity \"features\"\n",
    "    #followed by a color histogram to characterize the color distribution of the pixels\n",
    "    # in the image\n",
    "    pixels = image_to_feature_vector(image)\n",
    "    hist = extract_color_histogram(image)\n",
    "    # add the messages we got to the raw images, features, and labels matricies\n",
    "    rawImages.append(pixels)\n",
    "    features.append(hist)\n",
    "    labels.append(label)\n",
    "#conver numpy array in CNN network, -1 means how many featurs do we have and 1 means grey image\n",
    "#X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in testing_data:\n",
    "    testX.append(features)\n",
    "    testY.append(label)\n",
    "#conver numpy array in CNN network, -1 means how many featurs do we have and 1 means grey image\n",
    "testX = np.array(testX).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# loop over the input images\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # load the image and extract the class label\n",
    "    # our images were named as labels.image_number.format\n",
    "    image = cv2.imread(imagePath)\n",
    "    # get the labels from the name of the images by extract the string before \".\"\n",
    "    label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # show an update every 200 images until the last image\n",
    "    if i > 0 and ((i + 1)% 200 == 0 or i ==len(imagePaths)-1):\n",
    "        print(\"[INFO] processed {}/{}\".format(i+1, len(imagePaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle for testr \n",
    "pickle_out = open(\"testX.pickle\", \"wb\")\n",
    "pickle.dump(testX, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"testY.pickle\", \"wb\")\n",
    "pickle.dump(testY, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "#test \n",
    "pickle_in = open(\"testX.pickle\", \"rb\")\n",
    "testX = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 35],\n",
       "        [ 33],\n",
       "        [ 55],\n",
       "        ...,\n",
       "        [177],\n",
       "        [176],\n",
       "        [173]],\n",
       "\n",
       "       [[ 28],\n",
       "        [ 32],\n",
       "        [ 39],\n",
       "        ...,\n",
       "        [180],\n",
       "        [180],\n",
       "        [178]],\n",
       "\n",
       "       [[ 29],\n",
       "        [ 27],\n",
       "        [ 53],\n",
       "        ...,\n",
       "        [180],\n",
       "        [181],\n",
       "        [180]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 13],\n",
       "        [ 15],\n",
       "        [ 16],\n",
       "        ...,\n",
       "        [146],\n",
       "        [144],\n",
       "        [141]],\n",
       "\n",
       "       [[ 22],\n",
       "        [ 14],\n",
       "        [ 14],\n",
       "        ...,\n",
       "        [142],\n",
       "        [139],\n",
       "        [135]],\n",
       "\n",
       "       [[ 21],\n",
       "        [ 14],\n",
       "        [ 15],\n",
       "        ...,\n",
       "        [136],\n",
       "        [132],\n",
       "        [127]]], dtype=uint8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12650, 50, 50, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = X/255\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12296, 50, 50, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = testX/255\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after above one can do CNN model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=train_x.shape[1:]))\n",
    "# batchnormalization\n",
    "# model.add(BatchNormalization(axis=bn_axis, name='bn_conv1'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(CATEGORIES), activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12650/12650 [==============================] - 120s 9ms/step - loss: 0.6633 - acc: 0.5942\n",
      "Epoch 2/5\n",
      "12650/12650 [==============================] - 120s 9ms/step - loss: 0.5858 - acc: 0.6910\n",
      "Epoch 3/5\n",
      "12650/12650 [==============================] - 118s 9ms/step - loss: 0.5481 - acc: 0.7250\n",
      "Epoch 4/5\n",
      "12650/12650 [==============================] - 118s 9ms/step - loss: 0.5190 - acc: 0.7440\n",
      "Epoch 5/5\n",
      "12650/12650 [==============================] - 118s 9ms/step - loss: 0.4999 - acc: 0.7558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f50c9556a0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1384576   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,385,474\n",
      "Trainable params: 1,385,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-a8d8d779d2c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtesting_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "testing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_x, testY)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "test_labels[100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
